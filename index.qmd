---
title: Sockeye Introduction
author: Tony Liang
institute: University of British Columbia
date: 2023-09-27
date-format: long
engine: knitr
css: 
  - materials/sockeye.css
format:
  revealjs:
    logo: materials/img/logo.png
    slide-number: true
    #chalkboard: true
    template-partials:
      - title-slide.html
    embed-resources: true
    width: 1600
    height: 900
    mouse-wheel: true
    scrollable: false
    code-overflow: wrap
    hash-type: number
    link-external-icon: true
    link-external-newwindow: true
    lang: en-CA
    theme:
      - sockeye.scss
    output-file: index.html # naming other stuff, gh complains
    transition: fade
    transition-speed: default # or fast or slow
---

## Land acknowledgement


<!----------------------------Two column section------------------------------------>
:::: {.columns}

::: {.column width="70%"}
**I would like to acknowledge that I work on the traditional, ancestral, and unceded territory of the Coast Salish Peoples, including the territories of the xwməθkwəy̓əm (Musqueam), Skwxwú7mesh (Squamish), Stó:lō and Səl̓ílwətaʔ/Selilwitulh (Tsleil- Waututh) Nations.**

*Traditional*: Traditionally used and/or occupied by Musqueam people

*Ancestral*: Recognizes land that is handed down from generation to generation

*Unceded*: Refers to land that was not turned over to the Crown (government) by a treaty or other agreement

:::

::: {.column width="30%"}

![](materials/img/land_acknowledgement.gif)

:::

::::


## Setup VSCode

Checkout the instruction of your right platform below:

<!------------------------- Panel Tab for setup-------------------------------->


:::: {.panel-tabset}

### MacOs

Open this **[link](https://code.visualstudio.com/sha/download?build=stable&os=darwin-universal)** to download, once it is finished:

1. Open the downloaded `VSCode-darwin-universal.zip` file
2. Move the extracted VS Code app from `Downloads` to `Applications` (Located to your left under `Favorites`)
3. Launch VS Code and open the `Command Palette` by `Cmd + Shift + P`
4. Type `shell command`
5. Select the option: **Install `code` command in PATH**
6. Restart your terminal and try entering: `code --version` to confirm successful installation


### Windows

Open this **[link](https://code.visualstudio.com/sha/download?build=stable&os=win32-x64-user)** to download.

:::: {.columns}

::: {.column width="50%"}

Run the installer, accept default config except:

 - **On Select Additional Tasks**
    - Add 'Open with Code action to Windows file context menu'
    - Add ‘Open with Code’ action to Windows directory context menu”
    - Register Code as an editor for supported file types
    - Add to PATH (should be selected by default)

:::

::: {.column width="50%"}

<!-- ![](materials/img/windows_vsc.png){.absolute top=225 right=25 width="750" height="600"} -->
![](materials/img/windows_vsc.png){.absolute top=275 right=25 width="750" height="600"}

:::

::::


::::


## Connecting to Sockeye

::::: {.columns}

:::: {.column width="52%"}

::: {.callout-note}

You need to have a UBC IP address in order to access to the server by connecting to *eduroam* or 
*ubcsecure*

:::

Login to sockeye with the `ssh` command:
```{bash}
#| include: true
#| eval:  false
#| echo:  true
#| code-line-numbers: true
ssh cwl@sockeye.arc.ubc.ca
```


<!-- ::: {.incremental} -->

- `cwl` is your campus wide login

- password is your same CWL password

- `sockeye.arc.ubc.ca` is the server address

- you also need Two-Factor Authentication [2FA]{.secondary}

<!-- ::: -->

::::

:::: {.column width="48%"}

![](materials/img/sockeye_login.png){.absolute top=0 right=25 width="650" height="800"}

::::

:::::

## Alternative way connecting to Sockeye

<!-- ::: {.callout-tip}

You probably tired of typing password over and over to login to server, we could make more use of `ssh`

::: -->

:::: {.columns}

::: {.column width="60%"}

<!-- ::: {.incremental} -->

1. Generate new  `ssh` key pair credentials in your local
2. Add the [public]{.secondary} key to the server-side
3. Add your server login info into `~/.ssh/config` in your local
4. Login with `ssh <new_alias>`
  
<!-- ::: -->

:::

::: {.column width="40%"}

::: {.fragment .fade-in-then-semi-out}

Generate a new `ssh` key pair 

```{bash}
#| include: true
#| eval:  false
#| echo:  true
#| code-line-numbers: true
ssh-keygen -t rsa
```

- Follow default by prompting `Enter`
- Passphrase optional
- Two keys generated:
  * one public (`id_rsa.pub`)
  * one [private]{.third} (`id_rsa`)

:::

:::

::::

. . .

::: {.callout-caution}

Keep the [private]{.third} key safe and for your use only

:::

## Alternative way connecting to Sockeye
Add your **public** key to the server

::: {.panel-tabset}

### Bash/Zsh

```{bash}
#| eval:  false
#| echo: true
#| code-line-numbers: "2"
# Need to replace cwl!
ssh-copy-id -i ~/.ssh/id_rsa.pub
```

### Powershell

```{bash}
#| eval:  false
#| echo: true
#| code-line-numbers: "2"
#| code-overflow: scroll
# Need to replace cwl!
type $env:USERPROFILE\.ssh\id_rsa.pub | ssh cwl@sockeye.arc.ubc.ca "cat >> .ssh/authorized_keys"
```

:::


::: {.fragment .fade-up}

:::: {.columns}

::: {.column width="70%"}

Use any editor to create `~/.ssh/config` and enter the following:
```{bash}
#| eval:  false
#| echo:  true
#| code-line-numbers: "|2|3|4|2-4"
# Note these indent matters
Host  arc # or another alias you like
  HostName sockeye.arc.ubc.ca
  User cwl # replace your cwl
```

:::

::: {.column width="30%"}

<br>


- [Host = User@Hostname]{.secondary}
- Multiple configuration (multiple servers)
- More options available , look at [here](https://www.ssh.com/academy/ssh/config)

:::

::::

:::

::: aside

If you feel instructions unclear, follow this [guide](https://tonyliang19.github.io/arc-sockeye/#41)

:::





## Sockeye 

```{bash}
#| code-line-numbers: true
#| eval:  false
#| echo:  true
# If you followed earlier configuration correctly
ssh arc # otherwise ssh cwl@sockeye.arc.ubc.ca
```

<!-- ::: {.incremental} -->

- Upon login, you land on the `login` node and spend most time here
- Use it to run [large]{.secondary} computational works
- Whenever you're ready, you submit `batch` jobs to server
- You can log out and leave a job running
- Runs with `PBS`, changing to `SLURM`^[Please see [here](https://confluence.it.ubc.ca/display/UARC/PBS+to+Slurm+Migration+-+What+to+expect) for more info.] soon


<!-- ::: -->

. . .

::: {.callout-tip}

We also have a recorded session from past months, if you're interested please contact Amrit

:::

:::{.aside}
Sockeye is named after the Sockeye salmon (Oncorhyncus nerka), native to the Northern Pacific Ocean and the rivers discharging into it.
:::

---

![](materials/img/arc-structure.jpg)


## Directories on Sockeye

:::: {.columns}

::: {.column width="54%"}

![](materials/img/arc-dir.png)

:::



::: {.column width="46%"}

::: {.fragment .fade-up}

![](materials/img/ro-dir.png)

:::

:::

::::

. . .

::: {.callout-tip}

Remember that `read/write` access matters! You clearly don't want to spend hours fitting models, but failed to write any results, cause you forgot to specify it to be the **scratch** directory.

:::

## VScode in Sockeye

Using direct text editors like [nano]{.secondary} or [vi/vim]{.secondary} could be hard (steep learning curve)

So, use VSCode instead!

<br>

. . .

:::: {.columns}

::: {.column width="50%"}

1. Open local terminal and prompt `code`

2. Press `Ctrl + Shift + X`

3. Type `Remote - SSH` in search bar

4. Open first option and click `install`

:::

::: {.column width="50%"}

![](materials/img/ssh-install.png)

:::

::::

## Accessing softwares

<!-- :::: {.columns}

::: {.column width="30%"} -->

- Once you connect with `ssh`:
- There are no applications loaded
- You must tell system what you need
- Limited options, if need more try `container` or `conda`
<!-- 
::: -->

<!-- ::: {.column width="70%"}

Compare the difference of these two:

```{bash}
#| code-line-numbers: "|2|4"
#| eval:  false
#| echo:  true
# Try this and see what it gives you
module load gcc/7.5.0 python/3.7.10 && python --version
# Try this and see what it gives you
module purge && python --version
```

::: -->

<!-- :::: -->

. . .

[Useful commands]{.secondary}

```{bash}
#| code-line-numbers: "|1|3|7|8|1,3,7,8"
#| eval: false
#| echo: true

module load bin1/x.y.z bin2/x.y.z # load two modules and their versions
module purge # unload all modules
module list # what you have loaded
module save name_col # save loaded modules to "<name_col>"
module savelist # list saved collections (<name col> this case)
module restore name_col # load saved collection
module avail # show all available modules
module spider mod_name # check available `<mod_name>` in sockeye
```


## Example Job Script

::: {.callout-note .cus-small}

There are [no internet access]{.secondary} during any of the jobs below:

:::

::: {.panel-tabset .small-code}

### Batch Job CPU only

:::: {.columns}

::: {.column width="50%"}

```{bash}
#| eval: false
#| echo: true
#| code-line-numbers: "|2|4|6|7,8|10-11|"

#!/bin/bash
#PBS -l walltime=00:05:00, select=1:ncpus=2:mem=2gb
#PBS -N sample_job
#PBS -A st-singha53-1
#PBS -m abe
#PBS -M tliang19@student.ubc.ca
#PBS -o my_output.txt
#PBS -e my_error.txt

cd ${PBS_O_WORKDIR}
python hello_world.py
```

:::

::: {.column width="50%" .cus-small}

- This asks for 5 min of compute time with 2 cpus and 2GB of RAM
- You would expect much larger resources in complex scenarios
- Also, modules/environments/shell codes
- Most kinds of jobs falls to this category


:::

::::

### Batch Job (With GPU)

:::: {.columns}

::: {.column width="60%"}

```{bash}
#| eval: false
#| echo: true
#| code-line-numbers: true

#!/bin/bash
#PBS -l walltime=12:00:00, select=1:ncpus=4:ngpus=2:mem=64gb
#PBS -N sample_job_gpu
#PBS -A st-singha53-1-gpu
#PBS -M tliang19@student.ubc.ca
#PBS -o my_output.txt
#PBS -e my_error.txt

# load modules
module load gcc apptainer cuda

cd ${PBS_O_WORKDIR}
python hello_world.py
```

:::

::: {.column width="40%" .cus-small}

- This asks for 12 hours of comp. time, 1 node with 4 cpus and 2 gpus, **AND** 64GB RAM
- Need to specify number of gpus at `ngpus`
- Only allows 32G or 64G of memory for GPU
- Special allocation code, with `st-alloc-gpu`
- Probably runs this when your works uses neural networks

:::

::::

### Interactive CPU Job

:::: {.columns}

::: {.column width="60%"}

```{bash}
#| eval: false
#| echo: true
#| code-line-numbers: true

#!/bin/bash
#PBS -l walltime=3:00:00,select=1:ncpus=4:mem=16gb
#PBS -I
#PBS -q interactive_cpu
#PBS -N sample_job
#PBS -A st-singha53-1

# Note here should be empty, since you will get back a bash shell 
# with the requested resources in the script.
# And this ones are recommended to use, 
# when you have simple experiments to conduct without GPU
```

:::

::: {.column width="40%" .cus-small}

- This ask for a interactive node (shell) of 3 hours , with 4 cpus , with 16GB of RAM
- The `#PBS -I` and `#PBS -q interactive_cpu` are required to make a job interactive with CPU
- Otherwise job will be treated as a standard batch job
- Use this to test small computations or functionalitys of libraries you aim to use

:::

::::

### Interactive GPU Job

:::: {.columns}

::: {.column width="63%"}

```{bash}
#| eval: false
#| echo: true
#| code-line-numbers: true

#!/bin/bash
#PBS -l walltime=3:00:00,select=1:ncpus=4:ngpus=1:mem=16gb
#PBS -I
#PBS -q interactive_gpu
#PBS -N sample_job
#PBS -A st-singha53-1

# Note here should be empty, since you will get back a bash shell 
# with the requested resources in the script.
# And this ones are recommended to use, when you have simple experiments
# to conduct that uses GPU.
```

:::

::: {.column width="37%" .cus-small}

- This ask for a interactive node (shell) of 3 hours , with 4 cpus and 1 gpu , with 16GB of RAM
- Same as the `interactive job with cpu` but with GPU support
- Don't need the special code `st-alloc-gpu`
- Barely used it before, but Sockeye has this available

:::

::::

:::

<!-- ^ Tabset ended here ---->


::: {.aside .cus-smaller}

For more information on writing job scripts, checkout sockeye's official [documentation.](https://confluence.it.ubc.ca/display/UARC/Running+Jobs#RunningJobs-BatchJobScripts)

::: 

## Submitting and other useful commands

- Suppose our `pbs` script is saved as `job_script.sh`

::: {.small-code}
```{bash}
#| eval: false
#| echo: true
#| code-line-numbers: "|1|3|5|7|1,3,5,7|"
qsub job_script.sh # to submit job

qsub -u $USER # $USER is a pre-defined ENV variable

qdel some_job_id # some_job_id is from after submmision

qstat -x some_job_id # see resource comsumption of job
```

:::

. . .

::: {.callout-important}

1. On Sockeye, jobs must be run from `~/scratch/` only.
2. There are [no internet access]{.secondary} on the compute nodes (launched jobs). 

:::

<!-- ::: {.cus-smaller .small-code}

When I'm ready to run, I call something like:

```{bash}
#| eval: false
#| echo: true

qsub job_script.pbs # or job_script.sh
```

::: -->


## Summary workflow

1. Login via `ssh`
2. Modify your job script
    - required modules
    - required environment
    - required resources
3. Submit job
4. Inspect results
5. Pray and repeat until success!

::: {.callout-tip}

We are building our lab handbook with known FAQs for debugging on Sockeye, check out [here](https://compbio-lab.github.io/)

:::

<!-- ![](materials/img/website_bkg.png) -->

## {background-image=materials/img/website_bkg.png background-size=contain background-position=top}


[Thanks!]{.larger .center-custom}
